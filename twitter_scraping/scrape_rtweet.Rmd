---
title: "Scrape with rtweet"
author: "Zhaohan Dong"
date: '2022-05-25'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries

We will use the librarires rtweet and tidyverse.

```{r message=FALSE}
library(rtweet, quietly = TRUE)
library(tidyverse, quietly = TRUE)
```

## Load target tweet IDs

Load the tweet_id from the csv file and store as strings.

```{r}
setwd("../")
tweet_id <- read_csv("data/1_Tweet_IDs.csv", col_types = "c") %>%
  # We know that we want data after 2011-04-01 and 53607605465128960 is the first one on that day
  filter(as.double(id) >= 53607605465128960)
```

## Define twitter look up function

```{r}
batch_lookup <- function(tweet_list) {
  # The lookup_statuses function only takes vectors, not strings
  lookup_statuses(unlist(tweet_list))
}
```

## Loop through the tweet IDs

```{r}
setwd("data")

i <- 1
if (!exists("tweet_collection")) {
  tweet_collection <- tibble()
}

while (i < nrow(tweet_id)) {
  # Start process timing
  ptm <- proc.time()
  
  # Start querying data
  print(paste("Processing", i, "to", i + 89999, "tweet ID"))
  result <- batch_lookup(tweet_id[i:(i + 89999),])

  print("Query time")
  print(proc.time() - ptm)

  # Saving data to csv
  filename <- paste("tweet_", i, ".csv", sep = "")
  save_as_csv(result, filename)
  print("CSV saved.")
  
  # Total batch timing
  print("Total batch time")
  print(proc.time() - ptm)
  print("-----")
  i <- i+90000
  
  # Sleep for 15 min total
  Sys.sleep(900 - (proc.time() - ptm)[3])
}
```
